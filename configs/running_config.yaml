# env config
grid_res: 0.1
physical_step_duration: 0.1

#  """ the resolution of bullet to occupancy map, one cell in occ map = 0.1 meter in bullet"""
dilation_size: 4
goal_reached_thresh: 0.5

# train
save_result_n: 1000
max_steps: 250
inference_duration: 0.2 # [s]

evaluate_every_n_training: 1000
evaluate_n_times: 100

reward_config_name: reward_config1

# choose from  inputs_config.yaml: input_multi_row_multi_sensor, input_multi_row_cnn, input_lidar_mlp, input_cnn
input_config_name: input_cnn

# choose from worlds_config.yaml: "corridor","cross","office","empty"
world_name: office

# choose from ddqn, ddqn_recurrent, ddpg, ddpg_recurrent, td3, td3_recurrent, sac
agent: sac

action_space: ContinuousVWActionSpace

# choose from lidar, vision, multi_vision
sensor_name: vision

# choose from [race_car, turtlebot, object_robot]
agent_robot_name: race_car
num_agents: 1

npc_robot_name: object_robot
#  pedestrian speed
npc_speed_range: [ 0.8, 1.2 ]
num_npc: 0

# choose from agent_sg_sampler1, agent_sg_corner_sampler1
agent_sg_sampler: agent_sg_opposite_baffle_sampler2
npc_sg_sampler: npc_sg_sampler1













